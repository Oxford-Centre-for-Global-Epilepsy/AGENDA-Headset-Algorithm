# =======================
# üèÜ Main Workflow Entry
#
#   Workflow Purpose: Preprocess the EEG data files in preparation for algorithm training
# ========================================================================
configfile: "config/config.yaml"

# Snakemake Rules to include
include: "rules/bandpass_filter_data.smk"
include: "rules/resample_data.smk"
include: "rules/convert_to_bipolar_montage.smk"
include: "rules/epoch_data.smk"
include: "rules/normalise_data_epochs.smk"
include: "rules/convert_to_hdf5.smk"
#include: "rules/prepare_tensor.smk"

# Define the order of the rules
#ruleorder: bandpass_filter_data > resample_data > convert_to_bipolar > epoch_data > normalise_epoched_data > convert_to_hdf5 > prepare_tensor
ruleorder: bandpass_filter_data > resample_data > convert_to_bipolar > epoch_data > normalise_epoched_data > convert_to_hdf5

# ‚úÖ Import `expand` for rule all
#from snakemake.utils import expand
import os

# üî• Get $DATA environment variable (ensure it's set)
DATA_PATH = os.getenv("DATA")
if not DATA_PATH:
    raise ValueError("ERROR: The $DATA environment variable is not set!")

data_edf = f"{DATA_PATH}/AGENDA-Headset-Algorithm/data/edf"
data_fif = f"{DATA_PATH}/AGENDA-Headset-Algorithm/data/fif"
data_hdf5 = f"{DATA_PATH}/AGENDA-Headset-Algorithm/data/hdf5"

# =================================================
# üîé Discover Raw Data EEG Files (in .edf format)
# =================================================

def discover_eeg_files(data_folder=None, file_extension=".EEG"):
    """Find all .EEG files in raw data directory"""
    eeg_files = []
    for root, _, files in os.walk(data_folder):
        for file in files:
            if file.endswith(file_extension):
                relative_path = os.path.relpath(os.path.join(root, file), data_folder)
                eeg_files.append(relative_path.replace(file_extension, ""))
    return eeg_files

# üèÜ ** Get list of the file paths to the EEG data (in .edf format) **
EDF_FILEPATHS = discover_eeg_files(data_folder=data_edf, file_extension=".edf")

print(f"‚úÖ All .EDF files for processing: {EDF_FILEPATHS}")

# Specify the spatial montages to use for the data
MONTAGES = ["19_channel", "17_channel_no_A1_A2"]

# Make a wildcard constraint for the available montages
wildcard_constraints:
    montage="19_channel|17_channel_no_A1_A2|17_channel_no_T3_T4|16_channel"

# =======================
# üèÅ Define rule all
# =======================
rule all:
    input:
        # Ensure all HDF5 files are created
        expand(data_hdf5 + "/{montage}/{sample}.h5", sample=EDF_FILEPATHS, montage=MONTAGES),
       
        # Ensure all tensors are processed
        #expand(data_hdf5 + "/{montage}/{sample}_tensor.done", sample=EDF_FILEPATHS, montage=MONTAGES)


#expand(data_fif + "/{montage}/{sample}_resampled.fif", sample=EDF_FILEPATHS, montage=MONTAGES)
#expand(data_fif + "/{montage}/{sample}_bipolar.fif", sample=EDF_FILEPATHS, montage=MONTAGES)
#expand(data_fif + "/{montage}/{sample}_epoched.fif", sample=EDF_FILEPATHS, montage=MONTAGES)
#expand(data_fif + "/{montage}/{sample}_normalised.fif", sample=EDF_FILEPATHS, montage=MONTAGES)
#expand(data_hdf5 + "/{montage}/{sample}.h5", sample=EDF_FILEPATHS, montage=MONTAGES)
